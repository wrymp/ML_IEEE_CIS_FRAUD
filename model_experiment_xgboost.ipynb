{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T13:56:15.319613Z","iopub.execute_input":"2025-04-26T13:56:15.320537Z","iopub.status.idle":"2025-04-26T13:56:15.673033Z","shell.execute_reply.started":"2025-04-26T13:56:15.320508Z","shell.execute_reply":"2025-04-26T13:56:15.672039Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\"Reduce memory usage of DataFrame by downcasting numeric types\"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object and col_type != 'category' and col != 'TransactionID' and 'ID' not in col:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    \n    end_mem = df.memory_usage().sum() / 1024**2\n    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n    print(f'Decreased by {100 * (start_mem - end_mem) / start_mem:.1f}%')\n    \n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install dagshub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mlflow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport dagshub\ndagshub.init(repo_owner='dshan21', repo_name='ML_ASS_2', mlflow=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"identity_train_file_path = \"/kaggle/input/ieee-fraud-detection/train_identity.csv\"\nidentity_df = pd.read_csv(identity_train_file_path)\ntransaction_train_file_path = \"/kaggle/input/ieee-fraud-detection/train_transaction.csv\"\ntransaction_df = pd.read_csv(transaction_train_file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlflow.set_experiment(\"XGBoost_Training\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FEATURE CLEANING","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nmerged_df = None\ny = None\n\nwith mlflow.start_run(run_name=\"XGBoost_Cleaning\"):\n    missing_cutoff = 0.9\n    merged_df = transaction_df.merge(identity_df, on='TransactionID', how='left')\n    # print(f\"Merged data shape: {merged_df.shape}\")\n    \n    y = merged_df['isFraud'].copy()\n    merged_df.drop(['isFraud', 'TransactionID'], axis=1, inplace=True)\n    \n    missing_rate = merged_df.isnull().mean()\n    high_missing_cols = missing_rate[missing_rate > missing_cutoff].index.tolist()\n    mlflow.log_param(\"high_missing_threshold\", missing_cutoff)\n    \n    high_missing_df = pd.DataFrame({\n        'column_name': high_missing_cols,\n        'missing_rate': [missing_rate[col] for col in high_missing_cols]\n    }).sort_values('missing_rate', ascending=False)\n    \n    high_missing_file = \"high_missing_columns.csv\"\n    high_missing_df.to_csv(high_missing_file, index=False)\n    \n    mlflow.log_artifact(high_missing_file)\n    \n    merged_df.drop(high_missing_cols, axis=1, inplace=True)\n    mlflow.log_param(\"removed_columns\", len(high_missing_cols))\n    \n    categorical_cols = merged_df.select_dtypes(include=['object']).columns.tolist()\n    numerical_cols = merged_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    # print(categorical_cols)\n    # print(numerical_cols)\n    \n    for col in numerical_cols:\n        if merged_df[col].isnull().sum() > 0:\n            merged_df[col] = merged_df[col].fillna(merged_df[col].median())\n    \n    for col in categorical_cols:\n        if merged_df[col].isnull().sum() > 0:\n            merged_df[col] = merged_df[col].fillna('Unknown')\n    categorical_encoder = OneHotEncoder()      \n    mlflow.log_param(\"categorical_col_repl_method\", categorical_encoder)\n    if isinstance(categorical_encoder, LabelEncoder):\n        for col in categorical_cols:\n            merged_df[col] = categorical_encoder.fit_transform(merged_df[col].astype(str)) \n    elif isinstance(categorical_encoder, OneHotEncoder):\n        for col in categorical_cols:\n            encoded_array = categorical_encoder.fit_transform(merged_df[col].astype(str).values.reshape(-1, 1))\n            encoded_cols = categorical_encoder.get_feature_names_out([col])\n            encoded_df = pd.DataFrame(encoded_array.toarray(), columns=encoded_cols, index=merged_df.index)\n            \n            merged_df.drop(columns=[col], inplace=True)\n            merged_df = pd.concat([merged_df, encoded_df], axis=1)\n    mlflow.log_param(\"final_feature_count\",  merged_df.shape[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"newframe = merged_df.copy()\nmerged_df = newframe\n\nmerged_df['transaction_day'] = merged_df['TransactionDT'] // (24 * 60 * 60)\nmerged_df['transaction_hour'] = (merged_df['TransactionDT'] % (24 * 60 * 60)) // (60 * 60)\nmerged_df['transaction_minute'] = ((merged_df['TransactionDT'] % (24 * 60 * 60)) % (60 * 60)) // 60\nmerged_df['transaction_second'] = merged_df['TransactionDT'] % 60\n\nmerged_df['day_of_week'] = merged_df['transaction_day'] % 7\nmerged_df['is_weekend'] = merged_df['day_of_week'].isin([0, 6]).astype(int)\n\nmerged_df.drop('TransactionDT', axis=1, inplace=True)\n\nmerged_df['amount_log'] = np.log1p(merged_df['TransactionAmt'])\nmerged_df['amount_decimal'] = merged_df['TransactionAmt'] - np.floor(merged_df['TransactionAmt'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FEATURE SELECTION","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nimport xgboost as xgb\n\nX_selected = None\nwith mlflow.start_run(run_name=\"XGBoost_Feature_Selection\"):\n    X_train, X_val, y_train, y_val = train_test_split(\n        merged_df, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    model = xgb.XGBClassifier(\n        n_estimators=100,\n        max_depth=5,\n        learning_rate=0.1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        min_child_weight=1,\n        random_state=42,\n        tree_method='hist',\n        eval_metric='auc',\n        early_stopping_rounds=50\n    )\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        verbose=False\n    )\n    \n    feature_importances = model.feature_importances_\n    feature_importance_df = pd.DataFrame({\n        'Feature': merged_df.columns,\n        'Importance': feature_importances\n    }).sort_values('Importance', ascending=False)\n    \n    top_n_features = 200\n    top_features = feature_importance_df.head(top_n_features)['Feature'].tolist()\n    \n    \n    X_selected = merged_df[top_features].copy()\n    \n    mlflow.log_param(\"feature_selection_method\", \"XGBoost_Importance\")\n    mlflow.log_param(\"top_n_features\", top_n_features)\n    \n    with open('top_features.txt', 'w') as f:\n        for feature in top_features:\n            f.write(f\"{feature}\\n\")\n    \n    feature_importance_df.to_csv('feature_importance.csv', index=False)\n    mlflow.log_artifact('feature_importance.csv')\n    mlflow.log_artifact('top_features.txt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL TRAINING","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix\n\nwith mlflow.start_run(run_name=\"XGBoost_Training\"):\n    run_id = mlflow.active_run().info.run_id\n    print(f\"MLflow Run ID: {run_id}\")\n    params = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'learning_rate': 0.05,\n        'max_depth': 5,\n        'min_child_weight': 1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'tree_method': 'hist',\n        'random_state': 42\n    }\n    \n    for param, value in params.items():\n        mlflow.log_param(param, value)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X_selected, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    mlflow.log_param(\"num_features\", X_selected.shape[1])\n    mlflow.log_param(\"dataset_size\", X_train.shape)\n    mlflow.log_param(\"test_size\", 0.2)\n    \n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dtest = xgb.DMatrix(X_test, label=y_test)\n    \n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=500,\n        evals=[(dtrain, 'train'), (dtest, 'test')],\n        early_stopping_rounds=50,\n        verbose_eval=100\n    )\n    \n    y_pred_proba = model.predict(dtest)\n    auc_score = roc_auc_score(y_test, y_pred_proba)\n    y_pred_binary = (y_pred_proba > 0.5).astype(int)\n    \n    mlflow.log_metric(\"auc\", auc_score)\n    mlflow.log_metric(\"best_iteration\", model.best_iteration)\n    \n    mlflow.xgboost.log_model(model,\n        \"xgboost_model\",\n        registered_model_name=\"FraudXgboostModel\")\n    \n    model_path = \"xgboost_model.json\"\n    model.save_model(model_path)\n    mlflow.log_artifact(model_path)\n    \n    feature_importance = model.get_score(importance_type='gain')\n    importance_df = pd.DataFrame({\n        'Feature': list(feature_importance.keys()),\n        'Importance': list(feature_importance.values())\n    }).sort_values('Importance', ascending=False)\n    \n    plt.figure(figsize=(12, 8))\n    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n    plt.title('Top 20 Features by Importance')\n    plt.tight_layout()\n    plt.savefig('feature_importance.png')\n    plt.close()\n    \n    mlflow.log_artifact('feature_importance.png')\n    \n    pipeline_config = {\n        'model_type': 'XGBoost',\n        'feature_selection': 'importance_based',\n        'top_features': list(X_selected.columns),  # Assuming top_features is the column names\n        'preprocessing': 'Label encoding for categoricals, median imputation for numericals',\n        'model_params': params,\n        'auc_score': float(auc_score)  # Convert numpy float to Python float for JSON serialization\n    }\n    \n    import json\n    with open('pipeline_config.json', 'w') as f:\n        json.dump(pipeline_config, f, indent=4)\n    \n    mlflow.log_artifact('pipeline_config.json')\n    \n    print(f\"AUC Score: {auc_score:.4f}\")\n    print(f\"Best Iteration: {model.best_iteration}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}