# IEEE-CIS Fraud Detection
კონკურსის მიზანი იყო, რომ მოცემული ტრანზაქციების მონაცემების მიხედვით შეგვექმნა მოდელი,
რომელიც ახალ მონაცემებს თაღლითობაზე შეაფასებდა.
ჩემი მიდგომა იყო რომ ჯერ დამეთრეინებინა მოდელი 80%-ზე და დასტური მიმეღო 20%-ით kflod მეთოდით.

# რეპოზიტორიის სტრუქტურა
model_experiment_{მოდელის_ტიპი}.ipynb - აქ ვიმუშავე საწყის მონაცემებზე. გადავამუშავე/გადავაკეთე/გადავარჩიე და ასევე ვიპოვე საუკეთესო pipeline-ი ყოველი ტიპის მოდელისთვის
model_inference.ipynb - აქ შევქმენი საბმიშენი სატესტო მონაცემებით

# Feature Cleaning
დავიწყე იმით, რომ ორივე მადიგა გავაერთიანე ჯოინით. შემდგომ მონაცემები შევავსე მედიანით (რიცხვობრივი ცვლადებისთვის) და "Unknown"-ით კატეგორიულებისთვის.
ბოლოს უნდა ამერჩია როგორ დამეენკოდებინა კატეგორიული ცვლადები. labelEncoder-სა და OHE-ს შორის ავირჩიე პირველი, რადგან ნაკლები ზომის მაგიდები მომცა + kaggle არ დაქრეშა 
ზედმეტი რესურსების მოთხოვნით.

# Feature Engineering
აქ უბრალოდ დტ ცვლადი გადავიყვანე უფრო გასაგებ დროის მონაცემებში (თვე, კვირის დღე, საათი ...).
სხვა ცვლადებს სახელი აშიფრული ჰქონდათ და ვერაფერი მოვიფიქრე.

# Feature Selection
აქ პირდაპირ დავატრეინე პატარა საბსეტი 80/20 წესით და ავირჩიე ტოპ 200 სვეტი მნიშვნელობის მიხედვით. 

# Training
გამოვცადე შემდეგი მოდელები:
 **Random Forest Regressor** 
 **XGBoost** 
 **LightBGM** 

საბოლოო მოდელის შერჩევა მოხდა auc score-ების საფუძველზე.
აქვე აღვნიშნავ, რომ საუკეთესო შედეგი XGBoostმა მოიტანა და ყველაზე მეტი მაგაზე ვიწვალე.
# MLflow Tracking
**MLflow ექსპერიმენტების ბმული**: https://dagshub.com/dshan21/ML_ASS_2.mlflow/#/experiments/3?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

**ჩაწერილი მეტრიკები**:
 `auc`
 `best_iteration`
 
**საუკეთესო მოდელის შედეგები**:
Metric         Value
auc            0.9295797344141896
best_iteration 499

 საუკეთესო შედეგი:
 ![image](https://github.com/user-attachments/assets/3ac6db58-cbf3-43da-90be-db6842d2ee4c)



